{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tokenizer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJ+FTpeNJdFLqi3jr4+hlD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iewandowski/LP_Tokenizer/blob/main/tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "g0ZQSmEYnU0_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpMWhUDuDy1P",
        "outputId": "eca3d8f8-fa13-406d-d31d-01dca8f6f3f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "( a:= )\n",
            "(' ( ', ['LPAREN', 3] )\n",
            "( aux )\n",
            "(' - ', ['SUB_OP', 6] )\n",
            "( 2 )\n",
            "(' ) ', ['RPAREN', 4] )\n",
            "(  )\n",
            "(' * ', ['MUL_OP', 7] )\n",
            "( 200 )\n",
            "(' / ', ['DIV_OP', 8] )\n"
          ]
        }
      ],
      "source": [
        "texto = []\n",
        "vars = \"\"\n",
        "num = 0\n",
        "others = {1: [\"IDENT\", vars],\n",
        "          2: [\"INT_LIT\", num]\n",
        "          }\n",
        "\n",
        "\n",
        "tokens = {\"(\": [\"LPAREN\", 3], \n",
        "          \")\": [\"RPAREN\", 4], \n",
        "          \"+\": [\"ADD_OP\", 5], \n",
        "          \"-\": [\"SUB_OP\", 6], \n",
        "          \"*\": [\"MUL_OP\", 7], \n",
        "          \"/\": [\"DIV_OP\", 8], \n",
        "          \">\": [\"GT_OP\", 9],\n",
        "          \"<\": [\"LT_OP\", 10], \n",
        "          \"==\": [\"EQ_OP\", 11], \n",
        "          \":=\": [\"ASSIGN_OP\", 12]\n",
        "          }\n",
        "\n",
        "with open('line.txt') as file:\n",
        "  for linha in file:\n",
        "     txt = linha\n",
        "     texto = txt.replace(\" \", \"\")\n",
        "  for ch1, ch2, ch3 in zip(texto, texto[1:], texto[2:]):\n",
        "    char = ch2 + ch3\n",
        "    if ch1 not in tokens.keys():\n",
        "      vars = vars + ch1\n",
        "    elif ch2 or char in tokens.keys():\n",
        "      print(\"(\", vars, \")\")\n",
        "      vars = \"\"\n",
        "    if ch1 in tokens.keys():\n",
        "      print(\"('\", ch1, \"',\", tokens.get(str(ch1)), \")\")"
      ]
    }
  ]
}